#!/usr/bin/env python3
"""
æ”¹å–„ç‰ˆäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - ç²¾åº¦80%ä»¥ä¸Šã‚’ç›®æŒ‡ã™
"""
import json
import pickle
from pathlib import Path

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, classification_report, average_precision_score


def get_player_features(player_name: str, player_stats: dict, track: str = None,
                        grade: str = None, category: str = None) -> dict:
    """é¸æ‰‹ã®è©³ç´°ãªç‰¹å¾´é‡ã‚’å–å¾—"""
    if player_name not in player_stats:
        # æœªçŸ¥ã®é¸æ‰‹ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            "win_rate": 0.1,
            "place_2_rate": 0.1,
            "place_3_rate": 0.1,
            "top3_rate": 0.3,
            "avg_payout": 5000,
            "high_payout_rate": 0.2,
            "races": 0.0,
            "recent_win_rate": 0.1,
            "recent_top3_rate": 0.3,
            "track_win_rate": 0.1,
            "grade_win_rate": 0.1,
            "category_win_rate": 0.1,
            "consistency": 0.0,
        }

    stats = player_stats[player_name]

    # åŸºæœ¬çµ±è¨ˆ
    features = {
        "win_rate": stats["win_rate"],
        "place_2_rate": stats["place_2_rate"],
        "place_3_rate": stats["place_3_rate"],
        "top3_rate": stats["top3_rate"],
        "avg_payout": stats["avg_payout"],
        "high_payout_rate": stats["high_payout_rate"],
        "races": min(stats["races"], 500) / 500,
    }

    # æœ€è¿‘ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    features["recent_win_rate"] = stats.get("recent_win_rate", stats["win_rate"])
    features["recent_top3_rate"] = stats.get("recent_top3_rate", stats["top3_rate"])

    # å ´æ‰€åˆ¥å‹ç‡
    if track and track in stats.get("by_track", {}):
        features["track_win_rate"] = stats["by_track"][track]["win_rate"]
    else:
        features["track_win_rate"] = stats["win_rate"]

    # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥å‹ç‡
    if grade and grade in stats.get("by_grade", {}):
        features["grade_win_rate"] = stats["by_grade"][grade]["win_rate"]
    else:
        features["grade_win_rate"] = stats["win_rate"]

    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å‹ç‡
    if category and category in stats.get("by_category", {}):
        features["category_win_rate"] = stats["by_category"][category]["win_rate"]
    else:
        features["category_win_rate"] = stats["win_rate"]

    # å®‰å®šæ€§ï¼ˆæœ€è¿‘ã®æˆç¸¾ã¨å…¨ä½“ã®æˆç¸¾ã®å·®ï¼‰
    features["consistency"] = 1.0 - abs(features["recent_win_rate"] - stats["win_rate"])

    return features


def build_features(df: pd.DataFrame, player_stats: dict) -> tuple:
    """æ”¹å–„ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’æ§‹ç¯‰"""
    print("\nç‰¹å¾´é‡ã‚’æ§‹ç¯‰ä¸­...")

    X_list = []
    y_list = []

    for idx, row in df.iterrows():
        if idx % 10000 == 0:
            print(f"  å‡¦ç†ä¸­: {idx}/{len(df)} ãƒ¬ãƒ¼ã‚¹")

        # ãƒ©ãƒ™ãƒ«
        trifecta_payout = row.get("trifecta_payout", "0å††")
        try:
            payout = int(str(trifecta_payout).replace("å††", "").replace(",", ""))
        except:
            payout = 0

        y = 1 if payout >= 10000 else 0

        # ãƒ¬ãƒ¼ã‚¹æƒ…å ±
        track = row.get("track", "ä¸æ˜")
        grade = row.get("grade", "ä¸æ˜")
        category = row.get("category", "ä¸æ˜")

        # é¸æ‰‹å
        pos1_name = row.get("pos1_name")
        pos2_name = row.get("pos2_name")
        pos3_name = row.get("pos3_name")

        if pd.isna(pos1_name) or pd.isna(pos2_name) or pd.isna(pos3_name):
            continue

        # é¸æ‰‹çµ±è¨ˆã‚’å–å¾—ï¼ˆå ´æ‰€ãƒ»ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ»ã‚«ãƒ†ã‚´ãƒªãƒ¼è€ƒæ…®ï¼‰
        pos1_stats = get_player_features(pos1_name, player_stats, track, grade, category)
        pos2_stats = get_player_features(pos2_name, player_stats, track, grade, category)
        pos3_stats = get_player_features(pos3_name, player_stats, track, grade, category)

        # è»Šç•ªï¼ˆNaNå¯¾ç­–ï¼‰
        pos1_car = row.get("pos1_car_no", 5)
        pos2_car = row.get("pos2_car_no", 5)
        pos3_car = row.get("pos3_car_no", 5)

        if pd.isna(pos1_car):
            pos1_car = 5
        if pd.isna(pos2_car):
            pos2_car = 5
        if pd.isna(pos3_car):
            pos3_car = 5

        pos1_car = int(pos1_car)
        pos2_car = int(pos2_car)
        pos3_car = int(pos3_car)

        # ç‰¹å¾´é‡ã‚’æ§‹ç¯‰
        features = {
            # é¸æ‰‹çµ±è¨ˆï¼ˆ1ç€ï¼‰ - 8ç‰¹å¾´é‡
            "pos1_win_rate": pos1_stats["win_rate"],
            "pos1_top3_rate": pos1_stats["top3_rate"],
            "pos1_avg_payout": pos1_stats["avg_payout"],
            "pos1_high_payout_rate": pos1_stats["high_payout_rate"],
            "pos1_recent_win_rate": pos1_stats["recent_win_rate"],
            "pos1_track_win_rate": pos1_stats["track_win_rate"],
            "pos1_grade_win_rate": pos1_stats["grade_win_rate"],
            "pos1_consistency": pos1_stats["consistency"],

            # é¸æ‰‹çµ±è¨ˆï¼ˆ2ç€ï¼‰ - 8ç‰¹å¾´é‡
            "pos2_win_rate": pos2_stats["win_rate"],
            "pos2_top3_rate": pos2_stats["top3_rate"],
            "pos2_avg_payout": pos2_stats["avg_payout"],
            "pos2_high_payout_rate": pos2_stats["high_payout_rate"],
            "pos2_recent_win_rate": pos2_stats["recent_win_rate"],
            "pos2_track_win_rate": pos2_stats["track_win_rate"],
            "pos2_grade_win_rate": pos2_stats["grade_win_rate"],
            "pos2_consistency": pos2_stats["consistency"],

            # é¸æ‰‹çµ±è¨ˆï¼ˆ3ç€ï¼‰ - 8ç‰¹å¾´é‡
            "pos3_win_rate": pos3_stats["win_rate"],
            "pos3_top3_rate": pos3_stats["top3_rate"],
            "pos3_avg_payout": pos3_stats["avg_payout"],
            "pos3_high_payout_rate": pos3_stats["high_payout_rate"],
            "pos3_recent_win_rate": pos3_stats["recent_win_rate"],
            "pos3_track_win_rate": pos3_stats["track_win_rate"],
            "pos3_grade_win_rate": pos3_stats["grade_win_rate"],
            "pos3_consistency": pos3_stats["consistency"],

            # 3é¸æ‰‹ã®çµ±è¨ˆçš„ç‰¹å¾´ - 12ç‰¹å¾´é‡
            "avg_win_rate": np.mean([pos1_stats["win_rate"], pos2_stats["win_rate"], pos3_stats["win_rate"]]),
            "std_win_rate": np.std([pos1_stats["win_rate"], pos2_stats["win_rate"], pos3_stats["win_rate"]]),
            "min_win_rate": np.min([pos1_stats["win_rate"], pos2_stats["win_rate"], pos3_stats["win_rate"]]),
            "max_win_rate": np.max([pos1_stats["win_rate"], pos2_stats["win_rate"], pos3_stats["win_rate"]]),

            "avg_recent_win_rate": np.mean([pos1_stats["recent_win_rate"], pos2_stats["recent_win_rate"], pos3_stats["recent_win_rate"]]),
            "std_recent_win_rate": np.std([pos1_stats["recent_win_rate"], pos2_stats["recent_win_rate"], pos3_stats["recent_win_rate"]]),

            "avg_track_win_rate": np.mean([pos1_stats["track_win_rate"], pos2_stats["track_win_rate"], pos3_stats["track_win_rate"]]),
            "std_track_win_rate": np.std([pos1_stats["track_win_rate"], pos2_stats["track_win_rate"], pos3_stats["track_win_rate"]]),

            "avg_high_payout_rate": np.mean([pos1_stats["high_payout_rate"], pos2_stats["high_payout_rate"], pos3_stats["high_payout_rate"]]),
            "std_high_payout_rate": np.std([pos1_stats["high_payout_rate"], pos2_stats["high_payout_rate"], pos3_stats["high_payout_rate"]]),

            "avg_consistency": np.mean([pos1_stats["consistency"], pos2_stats["consistency"], pos3_stats["consistency"]]),
            "win_rate_gap": pos1_stats["win_rate"] - pos3_stats["win_rate"],  # åŠ›ã®å·®

            # è»Šç•ªç‰¹å¾´ - 9ç‰¹å¾´é‡
            "pos1_car_no": pos1_car,
            "pos2_car_no": pos2_car,
            "pos3_car_no": pos3_car,
            "car_sum": pos1_car + pos2_car + pos3_car,
            "car_std": np.std([pos1_car, pos2_car, pos3_car]),
            "car_range": max(pos1_car, pos2_car, pos3_car) - min(pos1_car, pos2_car, pos3_car),
            "outer_count": sum(1 for c in [pos1_car, pos2_car, pos3_car] if c >= 7),
            "inner_count": sum(1 for c in [pos1_car, pos2_car, pos3_car] if c <= 3),
            "has_1_car": 1 if 1 in [pos1_car, pos2_car, pos3_car] else 0,

            # ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰ - 5ç‰¹å¾´é‡
            "is_F1": 1 if grade == "F1" else 0,
            "is_F2": 1 if grade == "F2" else 0,
            "is_G1": 1 if grade == "G1" else 0,
            "is_G2": 1 if grade == "G2" else 0,
            "is_G3": 1 if grade == "G3" else 0,
        }

        X_list.append(features)
        y_list.append(y)

    print(f"  å®Œäº†: {len(X_list)} ãƒ¬ãƒ¼ã‚¹")

    X = pd.DataFrame(X_list)
    y = np.array(y_list)

    print(f"\n  ç‰¹å¾´é‡æ•°: {X.shape[1]}")
    print(f"  é«˜é…å½“ãƒ¬ãƒ¼ã‚¹: {y.sum():,} / {len(y):,} ({y.mean()*100:.1f}%)")

    return X, y


def train_model_with_cv(X: pd.DataFrame, y: np.ndarray) -> tuple:
    """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
    print("\n[3/5] LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­ï¼ˆ5-Fold CVï¼‰...\n")

    # æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 63,
        'learning_rate': 0.03,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'min_child_samples': 20,
        'max_depth': 8,
        'lambda_l1': 0.1,
        'lambda_l2': 0.1,
        'min_split_gain': 0.01,
        'verbose': -1,
        'force_col_wise': True,
        'scale_pos_weight': 2.0,  # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–
    }

    # 5-Fold Cross Validation
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = []
    models = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
        print(f"Fold {fold}/5ã‚’å­¦ç¿’ä¸­...")

        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
        y_train_fold, y_val_fold = y[train_idx], y[val_idx]

        train_data = lgb.Dataset(X_train_fold, label=y_train_fold)
        val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)

        model = lgb.train(
            params,
            train_data,
            num_boost_round=1000,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=100, verbose=False),
                lgb.log_evaluation(period=0)  # ãƒ­ã‚°ã‚’æŠ‘åˆ¶
            ]
        )

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_pred = model.predict(X_val_fold, num_iteration=model.best_iteration)
        auc = roc_auc_score(y_val_fold, y_pred)
        cv_scores.append(auc)
        models.append(model)

        print(f"  Fold {fold} AUC: {auc:.4f}")

    print(f"\nå¹³å‡AUC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")

    # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    best_model = models[np.argmax(cv_scores)]

    return best_model, cv_scores


def evaluate_model(model, X_test: pd.DataFrame, y_test: np.ndarray) -> dict:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡"""
    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = (y_pred_proba >= 0.5).astype(int)

    auc = roc_auc_score(y_test, y_pred_proba)
    ap = average_precision_score(y_test, y_pred_proba)
    report = classification_report(y_test, y_pred, output_dict=True)

    print(f"\n  AUC: {auc:.4f}")
    print(f"  Average Precision: {ap:.4f}")
    print(f"  ç²¾åº¦: {report['accuracy']:.4f}")

    # ç‰¹å¾´é‡é‡è¦åº¦Top 15
    feature_importance = model.feature_importance(importance_type='gain')
    feature_names = X_test.columns.tolist()
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance
    }).sort_values('importance', ascending=False)

    print(f"\n  ç‰¹å¾´é‡é‡è¦åº¦Top 15:")
    for i, row in importance_df.head(15).iterrows():
        print(f"    {row['feature']:30s} {row['importance']:8.0f}")

    return {
        "auc": auc,
        "average_precision": ap,
        "classification_report": report,
        "feature_importance": importance_df.to_dict('records')
    }


def main():
    print("=" * 60)
    print("æ”¹å–„ç‰ˆäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ï¼ˆç›®æ¨™ç²¾åº¦: 80%ä»¥ä¸Šï¼‰")
    print("=" * 60)

    # ãƒ‘ã‚¹è¨­å®š
    csv_path = Path(__file__).parent.parent / "data" / "keirin_results_20240101_20251004.csv"
    player_stats_path = Path(__file__).parent / "models" / "player_stats_advanced.json"
    model_dir = Path(__file__).parent / "models"

    # [1/5] ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\n[1/5] ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    df = pd.read_csv(csv_path, encoding="utf-8-sig")
    print(f"  ãƒ¬ãƒ¼ã‚¹æ•°: {len(df):,}")

    with open(player_stats_path, "r", encoding="utf-8") as f:
        player_stats = json.load(f)
    print(f"  é¸æ‰‹æ•°: {len(player_stats):,}")

    # [2/5] ç‰¹å¾´é‡æ§‹ç¯‰
    print("\n[2/5] ç‰¹å¾´é‡ã‚’æ§‹ç¯‰ä¸­...")
    X, y = build_features(df, player_stats)

    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # [3/5] ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model, cv_scores = train_model_with_cv(X_train, y_train)

    # [4/5] ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    print("\n[4/5] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ä¸­...")
    metrics = evaluate_model(model, X_test, y_test)

    # [5/5] ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    print("\n[5/5] ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")
    model_dir.mkdir(parents=True, exist_ok=True)

    # LightGBMå½¢å¼ã§ä¿å­˜
    model.save_model(str(model_dir / "model_improved.txt"))

    # Pickleå½¢å¼ã§ä¿å­˜
    with open(model_dir / "model_improved.pkl", "wb") as f:
        pickle.dump(model, f)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
    with open(model_dir / "metrics_improved.json", "w", encoding="utf-8") as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)

    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¿å­˜
    model_info = {
        "feature_count": X.shape[1],
        "feature_names": X.columns.tolist(),
        "cv_scores": cv_scores,
        "test_auc": metrics["auc"],
        "test_accuracy": metrics["classification_report"]["accuracy"],
    }

    with open(model_dir / "model_improved_info.json", "w", encoding="utf-8") as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)

    print("\nâœ… å®Œäº†ï¼")
    print(f"  - model_improved.txt")
    print(f"  - model_improved.pkl")
    print(f"  - metrics_improved.json")
    print(f"  - model_improved_info.json")

    print("\n" + "=" * 60)
    print("ğŸ‰ æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã—ã¾ã—ãŸï¼")
    print(f"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {metrics['classification_report']['accuracy']*100:.2f}%")
    print(f"   CVå¹³å‡AUC: {np.mean(cv_scores):.4f}")
    print("=" * 60)


if __name__ == "__main__":
    main()
