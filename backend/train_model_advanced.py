#!/usr/bin/env python3
"""
ç«¶è¼ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨ä¿å­˜ï¼ˆé«˜ç²¾åº¦ç‰ˆï¼‰
LightGBM + é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
"""
import json
import pickle
import re
from pathlib import Path

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.metrics import (average_precision_score, classification_report,
                             roc_auc_score, confusion_matrix)
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import LabelEncoder


def parse_payout(value: str) -> float:
    """é…å½“é‡‘æ–‡å­—åˆ—ã‚’æ•°å€¤ã«å¤‰æ›"""
    if pd.isna(value) or value == "":
        return np.nan
    digits = re.sub(r"[^0-9]", "", str(value))
    return float(digits) if digits else np.nan


def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""

    # è»Šç•ªã®åŸºæœ¬çµ±è¨ˆé‡
    for pos in (1, 2, 3):
        df[f"pos{pos}_car_no"] = pd.to_numeric(df[f"pos{pos}_car_no"], errors="coerce")

    car_cols = ["pos1_car_no", "pos2_car_no", "pos3_car_no"]

    # åŸºæœ¬çµ±è¨ˆé‡
    df["car_sum"] = df[car_cols].sum(axis=1)
    df["car_std"] = df[car_cols].std(axis=1)
    df["car_range"] = df[car_cols].max(axis=1) - df[car_cols].min(axis=1)
    df["car_median"] = df[car_cols].median(axis=1)
    df["car_min"] = df[car_cols].min(axis=1)
    df["car_max"] = df[car_cols].max(axis=1)
    df["car_mean"] = df[car_cols].mean(axis=1)

    # é«˜åº¦ãªç‰¹å¾´é‡
    # 1. è»Šç•ªã®é€£ç¶šæ€§ï¼ˆ1-2-3ã®ã‚ˆã†ãªé€£ç•ªã‹ã©ã†ã‹ï¼‰
    df["is_consecutive"] = (
        ((df["pos2_car_no"] - df["pos1_car_no"]).abs() == 1) &
        ((df["pos3_car_no"] - df["pos2_car_no"]).abs() == 1)
    ).astype(int)

    # 2. è»Šç•ªã®å¶å¥‡ãƒ‘ã‚¿ãƒ¼ãƒ³
    df["odd_count"] = (df[car_cols] % 2).sum(axis=1)
    df["even_count"] = 3 - df["odd_count"]
    df["all_odd"] = (df["odd_count"] == 3).astype(int)
    df["all_even"] = (df["even_count"] == 3).astype(int)

    # 3. äººæ°—ã®åˆ†æ•£åº¦ï¼ˆè»Šç•ªã®ã°ã‚‰ã¤ãï¼‰
    df["car_variance"] = df[car_cols].var(axis=1)

    # 4. å¤§ç©´æŒ‡æ¨™ï¼ˆå¤–æ ãŒå¤šã„ã»ã©é«˜ã„ï¼‰
    df["outer_count"] = (df[car_cols] >= 7).sum(axis=1)
    df["inner_count"] = (df[car_cols] <= 3).sum(axis=1)

    # 5. è»Šç•ªã®ç©
    df["car_product"] = df["pos1_car_no"] * df["pos2_car_no"] * df["pos3_car_no"]

    # 6. è»Šç•ªã®å·®ã®çµ¶å¯¾å€¤
    df["diff_12"] = (df["pos1_car_no"] - df["pos2_car_no"]).abs()
    df["diff_23"] = (df["pos2_car_no"] - df["pos3_car_no"]).abs()
    df["diff_13"] = (df["pos1_car_no"] - df["pos3_car_no"]).abs()
    df["total_diff"] = df["diff_12"] + df["diff_23"] + df["diff_13"]

    # 7. è»Šç•ªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ˜‡é †ãƒ»é™é †ï¼‰
    df["is_ascending"] = (
        (df["pos1_car_no"] < df["pos2_car_no"]) &
        (df["pos2_car_no"] < df["pos3_car_no"])
    ).astype(int)
    df["is_descending"] = (
        (df["pos1_car_no"] > df["pos2_car_no"]) &
        (df["pos2_car_no"] > df["pos3_car_no"])
    ).astype(int)

    # 8. ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’æ•°å€¤åŒ–
    df["race_no_numeric"] = pd.to_numeric(
        df["race_no"].str.upper().str.replace("R", "", regex=False),
        errors="coerce"
    ).fillna(0)

    return df


def build_dataset(csv_path: Path) -> tuple:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰"""
    df = pd.read_csv(csv_path)
    df["trifecta_payout_value"] = df["trifecta_payout"].apply(parse_payout)
    df = df.dropna(subset=["trifecta_payout_value"])
    df["high_payout"] = (df["trifecta_payout_value"] >= 10000).astype(int)

    # é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ
    df = create_advanced_features(df)

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ã®å‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
    cat_cols = ["grade", "track", "category"]
    for col in cat_cols:
        df[col] = df[col].fillna("(æ¬ æ)").astype(str)

    # Label Encodingï¼ˆLightGBMã®ãŸã‚ï¼‰
    label_encoders = {}
    for col in cat_cols:
        le = LabelEncoder()
        df[f"{col}_encoded"] = le.fit_transform(df[col])
        label_encoders[col] = le

    # æ•°å€¤ç‰¹å¾´é‡
    numeric_cols = [
        "car_sum", "car_std", "car_range", "car_median", "car_min", "car_max", "car_mean",
        "car_variance", "outer_count", "inner_count", "car_product",
        "diff_12", "diff_23", "diff_13", "total_diff",
        "is_consecutive", "odd_count", "even_count", "all_odd", "all_even",
        "is_ascending", "is_descending", "race_no_numeric",
        "pos1_car_no", "pos2_car_no", "pos3_car_no"
    ]

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ï¼‰
    cat_encoded_cols = [f"{col}_encoded" for col in cat_cols]

    # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜ï¼ˆäºˆæ¸¬æ™‚ã«ä½¿ç”¨ï¼‰
    stats = {
        "numeric_cols": numeric_cols,
        "cat_cols": cat_cols,
        "cat_encoded_cols": cat_encoded_cols,
        "label_encoders": {col: list(le.classes_) for col, le in label_encoders.items()}
    }

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    feature_cols = numeric_cols + cat_encoded_cols
    X = df[feature_cols]
    y = df["high_payout"].values

    return X, y, df, stats


def train_model(X: pd.DataFrame, y: np.ndarray):
    """LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆèª¿æ•´æ¸ˆã¿ï¼‰
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'min_child_samples': 20,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'scale_pos_weight': len(y_train[y_train == 0]) / len(y_train[y_train == 1])
    }

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    train_data = lgb.Dataset(X_train, label=y_train)
    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = lgb.train(
        params,
        train_data,
        num_boost_round=1000,
        valid_sets=[train_data, test_data],
        valid_names=['train', 'valid'],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=100)
        ]
    )

    # äºˆæ¸¬
    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = (y_pred_proba >= 0.5).astype(int)

    # è©•ä¾¡æŒ‡æ¨™
    metrics = {
        "auc": float(roc_auc_score(y_test, y_pred_proba)),
        "average_precision": float(average_precision_score(y_test, y_pred_proba)),
        "classification_report": classification_report(y_test, y_pred, output_dict=True),
        "positive_rate": float(y.mean()),
        "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
    }

    # ç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importance(importance_type='gain')
    }).sort_values('importance', ascending=False)

    metrics["feature_importance"] = feature_importance.head(20).to_dict('records')

    return model, metrics


def main():
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    csv_path = Path("data/keirin_results_20240101_20251004.csv")
    if not csv_path.exists():
        raise SystemExit(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")

    print("=" * 60)
    print("é«˜ç²¾åº¦ç«¶è¼ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’")
    print("=" * 60)

    print("\n[1/4] ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ä¸­...")
    X, y, df, stats = build_dataset(csv_path)

    print(f"  ç·ãƒ¬ãƒ¼ã‚¹æ•°: {len(df):,}")
    print(f"  é«˜é…å½“ãƒ¬ãƒ¼ã‚¹æ•°: {df['high_payout'].sum():,} ({df['high_payout'].mean()*100:.1f}%)")
    print(f"  ç‰¹å¾´é‡æ•°: {X.shape[1]}")

    print("\n[2/4] LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    model, metrics = train_model(X, y)

    print(f"\n[3/4] ãƒ¢ãƒ‡ãƒ«è©•ä¾¡:")
    print(f"  AUC: {metrics['auc']:.4f}")
    print(f"  Average Precision: {metrics['average_precision']:.4f}")
    print(f"  ç²¾åº¦ï¼ˆå…¨ä½“ï¼‰: {metrics['classification_report']['accuracy']:.4f}")
    print(f"  å†ç¾ç‡ï¼ˆé«˜é…å½“ï¼‰: {metrics['classification_report']['1']['recall']:.4f}")
    print(f"  é©åˆç‡ï¼ˆé«˜é…å½“ï¼‰: {metrics['classification_report']['1']['precision']:.4f}")

    print("\n  ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ï¼‰:")
    for item in metrics['feature_importance'][:10]:
        print(f"    {item['feature']}: {item['importance']:.0f}")

    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
    model_dir = Path("backend/models")
    model_dir.mkdir(parents=True, exist_ok=True)

    print("\n[4/4] ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­...")

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ï¼ˆLightGBMå°‚ç”¨å½¢å¼ï¼‰
    model.save_model(str(model_dir / "model_lgb.txt"))

    # Pickleã§ã‚‚ä¿å­˜ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    with open(model_dir / "model.pkl", "wb") as f:
        pickle.dump(model, f)

    # çµ±è¨ˆæƒ…å ±ã®ä¿å­˜
    with open(model_dir / "model_stats.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    with open(model_dir / "metrics.json", "w", encoding="utf-8") as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)

    # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆUIã§ä½¿ç”¨ï¼‰
    reference_data = {
        "tracks": sorted(df["track"].unique().tolist()),
        "grades": sorted(df["grade"].unique().tolist()),
        "categories": sorted(df["category"].unique().tolist()),
    }

    with open(model_dir / "reference_data.json", "w", encoding="utf-8") as f:
        json.dump(reference_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å®Œäº†ï¼ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_dir}")
    print("  - model_lgb.txt (LightGBMãƒ¢ãƒ‡ãƒ«)")
    print("  - model.pkl (Pickleãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—)")
    print("  - model_stats.json (ç‰¹å¾´é‡æƒ…å ±)")
    print("  - metrics.json (è©•ä¾¡æŒ‡æ¨™)")
    print("  - reference_data.json (ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿)")

    print("\n" + "=" * 60)
    print("ğŸ‰ é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
